## 웹 크롤링

---

1. 크롤링 과정
    * URL 분석 (패턴 존재 여부, query 종류)
        * URL 긁어오기 -> query 분석

    * URL 구성 (변수화 -> str, 자동화 고려)
        * URL 분석한 것을 나누어서 쿼리 분류작업

            ```python
                word = '보람튜브' 
                URL = "https://search.naver.com/search.naver?where=news&query=" + word
            ```

    * HTTP Response 얻기
        * URL에서 내용 뽑아내기 // 뽑아낸 상태는 사람이 볼 수 없는 자료형태로 가공할 준비해야함

            ```python
                web = requests.get(URL).content # 또는 urlopen(URL) 함수를 통해서 변수화
                # urlopen함수는 ascii코드여서 한글이 깨져서 보람튜브 같은 쿼리를 넣을 수 없게 됨
            ```

    * HTML source 얻기
        * BeatifulSoup를 통해 parsing작업을 진행해야함
            > BeatifulSoup(HTTP Response, 'html.parser')

            ``` python
            source = BeautifulSoup(web, 'html.parser')
            ```

    * HTML Tag 꺼내기
        * 현재 HTML형태로 태그, 셀렉터가 모두 나왔으므로 필요한 정보(제목, 기사별URL 등)만 뽑아야함
            <details>
            <summary>find, findall 함수 펼치기</summary>
            <div markdown="1">
                        * .find('Tag이름', {'Attr 이름':'Attr 값'}) 1개의 Tag (조건이 동일한 Tag가 여러개면 첫번째만 꺼내줌)
                            > 바로 위 부모 태그를 감싸서 대입 시킴

                            ``` python
                            box1 = web_page.find('ul', {"class" : "list_search"}).get_text().replace('\n','')
                            ```

                        * .find_all(~) : 여러개의 Tag를 찾은 다음 for문으로 Tag 단위로 꺼내서 활용  
                            > 직접 태그를 감싸서 대입시키고 for문으로 get_text로 뽑아냄
            </div>
            </details>

        * 태그끼리 묶어내기

            ``` python
            news_subjects = source.find_all('a', {'class' : 'news_tit'}) # ResultSet (list와 유사한 형태)
            # 전체 HTML content에서 a태그 목록으로 전환하는 과정으로 a태그 끼리 묶어줌
            ```
            
            ```python
            subject_list = []

            for subject in news_subjects:
                subject_list.append(subject.get_text())

                print(subject_list)
                # find_all로 꺼내면 list
                print(span.get_text())  # ResultSet의 함수에는 get_text() 함수가 존재하지 않음
            ```
    * Tag로 부터 텍스트 혹은 Atrribute values 꺼내기 : Tag.get_text() or Tag.attrs
        ```python
            with open('brunch.txt','a',encoding = 'utf-8') as f: # 자동으로 닫아주는 코드 mode: 'a'
                all_text = source.find('div',{'class': 'wrap_body'}) # class wrp_body 하나만 가져옴
                article = all_text.find_all('p') # 부모 태그 안에 모든 'p' 태그를 가져와줌
        
            for content in article:
                print(content.get_text())
                f.write(content.get_text() + '\n')
2. 